import asyncio
import os
import yaml
import glob
import re
import aiofiles
from typing import List, Dict, Optional, AsyncGenerator
from pathlib import Path
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from backend.ssh_manager import SSHConnectionPool, RemoteFileReader

CONFIG_PATH = "config/settings.yaml"

# ANSI é¢œè‰²ä»£ç çš„æ­£åˆ™è¡¨è¾¾å¼ï¼ˆæ”¯æŒå¸¦å’Œä¸å¸¦ ESC å‰ç¼€çš„æ ¼å¼ï¼‰
ANSI_ESCAPE_PATTERN = re.compile(r'(\x1B\[[0-?]*[ -/]*[@-~]|\[[0-9;]+m)')

def strip_ansi_codes(text: str) -> str:
    """ç§»é™¤ ANSI é¢œè‰²ä»£ç """
    return ANSI_ESCAPE_PATTERN.sub('', text)


class FileWatcher(FileSystemEventHandler):
    """æ–‡ä»¶ç›‘æ§å¤„ç†å™¨ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    
    def __init__(self, file_path: str, event_flag: asyncio.Event, loop):
        self.file_path = file_path
        self.event_flag = event_flag
        self.loop = loop
        
    def on_modified(self, event):
        if not event.is_directory and event.src_path == self.file_path:
            # åœ¨ä¸»äº‹ä»¶å¾ªç¯ä¸­è®¾ç½®äº‹ä»¶ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
            self.loop.call_soon_threadsafe(self.event_flag.set)
    
    def on_created(self, event):
        if not event.is_directory and event.src_path == self.file_path:
            # åœ¨ä¸»äº‹ä»¶å¾ªç¯ä¸­è®¾ç½®äº‹ä»¶ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
            self.loop.call_soon_threadsafe(self.event_flag.set)


class LogManager:
    def __init__(self):
        self.config = self._load_config()
        self.files_map = self._build_files_map()
        
        # åˆå§‹åŒ– SSH è¿æ¥æ± å’Œè¿œç¨‹æ–‡ä»¶è¯»å–å™¨
        self.ssh_pool = SSHConnectionPool(max_connections=10, timeout=300)
        self.remote_reader = RemoteFileReader(self.ssh_pool)

    def _load_config(self) -> dict:
        if not os.path.exists(CONFIG_PATH):
            return {"log_files": [], "log_directories": []}
        with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)

    def _scan_directory(self, dir_config: dict) -> List[Dict]:
        """æ‰«æç›®å½•ï¼Œè¿”å›æ‰€æœ‰æ—¥å¿—æ–‡ä»¶"""
        scan_dir = dir_config.get("scan_dir")
        pattern = dir_config.get("pattern", "*.log")
        recursive = dir_config.get("recursive", True)
        encoding = dir_config.get("encoding", "utf-8")
        
        if not scan_dir or not os.path.exists(scan_dir):
            return []
        
        files = []
        search_pattern = os.path.join(scan_dir, "**", pattern) if recursive else os.path.join(scan_dir, pattern)
        
        for file_path in glob.glob(search_pattern, recursive=recursive):
            if os.path.isfile(file_path):
                # ç”Ÿæˆç›¸å¯¹äºæ‰«æç›®å½•çš„æ˜¾ç¤ºåç§°
                rel_path = os.path.relpath(file_path, scan_dir)
                files.append({
                    "name": rel_path,
                    "path": file_path,
                    "encoding": encoding,
                })
        
        return files

    def _build_tree_structure(self, files: List[Dict], base_name: str) -> List[Dict]:
        """å°†æ‰å¹³çš„æ–‡ä»¶åˆ—è¡¨è½¬æ¢ä¸ºæ ‘çŠ¶ç»“æ„"""
        tree = {}
        
        for file_info in files:
            rel_path = file_info["name"]
            path_parts = Path(rel_path).parts
            
            current_level = tree
            for i, part in enumerate(path_parts):
                if part not in current_level:
                    is_file = (i == len(path_parts) - 1)
                    if is_file:
                        # å¶å­èŠ‚ç‚¹ï¼ˆæ–‡ä»¶ï¼‰
                        unique_name = f"{base_name}/{rel_path}"
                        current_level[part] = {
                            "name": unique_name,
                            "label": part,  # åªæ˜¾ç¤ºæ–‡ä»¶å
                            "path": file_info["path"],
                            "encoding": file_info["encoding"],
                            "type": "file",
                            "is_leaf": True
                        }
                    else:
                        # ç›®å½•èŠ‚ç‚¹
                        current_level[part] = {
                            "name": part,
                            "label": part,  # åªæ˜¾ç¤ºç›®å½•å
                            "type": "directory",
                            "children": {}
                        }
                
                if not current_level[part].get("is_leaf"):
                    current_level = current_level[part]["children"]
        
        # å°†å­—å…¸è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
        def dict_to_list(node_dict):
            result = []
            for key, value in sorted(node_dict.items()):
                if value.get("type") == "directory":
                    result.append({
                        "name": value["name"],
                        "label": value["label"],
                        "type": "directory",
                        "children": dict_to_list(value["children"])
                    })
                else:
                    result.append({
                        "name": value["name"],
                        "label": value["label"],
                        "path": value["path"],
                        "exists": os.path.exists(value["path"]),
                        "size": os.path.getsize(value["path"]) if os.path.exists(value["path"]) else 0,
                        "type": "file"
                    })
            return result
        
        return dict_to_list(tree)

    def _build_files_map(self) -> Dict[str, dict]:
        """æ„å»ºæ–‡ä»¶ååˆ°é…ç½®çš„æ˜ å°„"""
        mapping = {}
        
        # æ·»åŠ æ‰‹åŠ¨é…ç½®çš„æ–‡ä»¶
        for item in self.config.get("log_files", []):
            mapping[item["name"]] = {
                **item,
                "source": "local"
            }
        
        # æ·»åŠ æ‰«æç›®å½•ä¸­çš„æ–‡ä»¶
        for dir_config in self.config.get("log_directories", []):
            base_name = dir_config.get("name", "Scanned")
            scanned_files = self._scan_directory(dir_config)
            for file_info in scanned_files:
                # ä½¿ç”¨å®Œæ•´è·¯å¾„ä½œä¸ºå”¯ä¸€æ ‡è¯†
                unique_name = f"{base_name}/{file_info['name']}"
                mapping[unique_name] = {
                    "path": file_info["path"],
                    "encoding": file_info["encoding"],
                    "source": "local"
                }
        
        # æ·»åŠ è¿œç¨‹æœåŠ¡å™¨çš„æ–‡ä»¶
        for server_config in self.config.get("remote_servers", []):
            server_name = server_config.get("name", "Remote")
            for log_config in server_config.get("logs", []):
                unique_name = f"{server_name}/{log_config['name']}"
                mapping[unique_name] = {
                    **log_config,
                    "source": "remote",
                    "server_config": server_config
                }
        
        return mapping

    async def _build_remote_tree(self, server_config: Dict) -> List[Dict]:
        """æ„å»ºè¿œç¨‹æœåŠ¡å™¨çš„æ–‡ä»¶æ ‘"""
        server_name = server_config.get("name", "Remote")
        tree_nodes = []
        
        for log_config in server_config.get("logs", []):
            log_name = log_config.get("name")
            log_type = log_config.get("type", "file")
            log_path = log_config.get("path")
            
            if log_type == "file":
                # å•ä¸ªæ–‡ä»¶
                unique_name = f"{server_name}/{log_name}"
                tree_nodes.append({
                    "name": unique_name,
                    "label": log_name,
                    "path": log_path,
                    "type": "file",
                    "source": "remote",
                    "exists": True  # è¿œç¨‹æ–‡ä»¶å‡è®¾å­˜åœ¨ï¼Œå®é™…è®¿é—®æ—¶å†éªŒè¯
                })
            elif log_type == "directory":
                # æ‰«æè¿œç¨‹ç›®å½•
                pattern = log_config.get("pattern", "*.log")
                recursive = log_config.get("recursive", False)
                
                remote_files = await self.remote_reader.list_files(
                    server_config, log_path, pattern, recursive
                )
                
                if remote_files:
                    # æ„å»ºå­æ ‘
                    dir_tree = self._build_remote_dir_tree(
                        remote_files, log_path, server_name, log_name
                    )
                    
                    # åˆ›å»ºç›®å½•èŠ‚ç‚¹
                    tree_nodes.append({
                        "name": f"{server_name}/{log_name}",
                        "label": log_name,
                        "type": "directory",
                        "children": dir_tree
                    })
        
        return tree_nodes
    
    def _build_remote_dir_tree(self, files: List[Dict], base_path: str, 
                               server_name: str, dir_name: str) -> List[Dict]:
        """æ„å»ºè¿œç¨‹ç›®å½•çš„æ ‘çŠ¶ç»“æ„"""
        tree = {}
        
        for file_info in files:
            file_path = file_info["path"]
            # è®¡ç®—ç›¸å¯¹è·¯å¾„
            rel_path = os.path.relpath(file_path, base_path)
            path_parts = Path(rel_path).parts
            
            current_level = tree
            for i, part in enumerate(path_parts):
                if part not in current_level:
                    is_file = (i == len(path_parts) - 1)
                    if is_file:
                        # æ–‡ä»¶èŠ‚ç‚¹
                        unique_name = f"{server_name}/{dir_name}/{rel_path}"
                        current_level[part] = {
                            "name": unique_name,
                            "label": part,
                            "path": file_path,
                            "type": "file",
                            "source": "remote",
                            "is_leaf": True
                        }
                    else:
                        # ç›®å½•èŠ‚ç‚¹
                        current_level[part] = {
                            "name": part,
                            "label": part,
                            "type": "directory",
                            "children": {}
                        }
                
                if not current_level[part].get("is_leaf"):
                    current_level = current_level[part]["children"]
        
        # è½¬æ¢ä¸ºåˆ—è¡¨
        def dict_to_list(node_dict):
            result = []
            for key, value in sorted(node_dict.items()):
                if value.get("type") == "directory":
                    result.append({
                        "name": value["name"],
                        "label": value["label"],
                        "type": "directory",
                        "children": dict_to_list(value["children"])
                    })
                else:
                    result.append({
                        "name": value["name"],
                        "label": value["label"],
                        "path": value["path"],
                        "type": "file",
                        "source": "remote",
                        "exists": True
                    })
            return result
        
        return dict_to_list(tree)

    def get_file_list(self) -> List[Dict]:
        """è·å–å¯ç”¨çš„æ–‡ä»¶åˆ—è¡¨ï¼Œæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼Œç”¨äºåˆå§‹åŒ–ï¼‰"""
        result = []
        
        # æ‰‹åŠ¨é…ç½®çš„æœ¬åœ°æ–‡ä»¶
        for file_conf in self.config.get("log_files", []):
            path = file_conf.get("path")
            exists = os.path.exists(path) if path else False
            result.append({
                "name": file_conf["name"],
                "label": file_conf["name"],
                "path": path,
                "exists": exists,
                "size": os.path.getsize(path) if exists else 0,
                "type": "file",
                "source": "local"
            })
        
        # æ‰«ææœ¬åœ°ç›®å½•
        for dir_config in self.config.get("log_directories", []):
            base_name = dir_config.get("name", "Scanned")
            scanned_files = self._scan_directory(dir_config)
            
            if scanned_files:
                tree_nodes = self._build_tree_structure(scanned_files, base_name)
                group_node = {
                    "name": base_name,
                    "label": base_name,
                    "type": "directory",
                    "source": "local",
                    "children": tree_nodes
                }
                result.append(group_node)
        
        return result
    
    async def get_file_list_async(self) -> List[Dict]:
        """è·å–å®Œæ•´æ–‡ä»¶åˆ—è¡¨ï¼ˆåŒ…æ‹¬è¿œç¨‹æœåŠ¡å™¨ï¼‰ï¼Œå¼‚æ­¥ç‰ˆæœ¬"""
        result = self.get_file_list()  # å…ˆè·å–æœ¬åœ°æ–‡ä»¶
        
        # æ·»åŠ è¿œç¨‹æœåŠ¡å™¨
        for server_config in self.config.get("remote_servers", []):
            server_name = server_config.get("name", "Remote")
            
            try:
                # æ„å»ºè¿œç¨‹æœåŠ¡å™¨çš„æ–‡ä»¶æ ‘
                remote_tree = await self._build_remote_tree(server_config)
                
                if remote_tree:
                    # åˆ›å»ºæœåŠ¡å™¨åˆ†ç»„èŠ‚ç‚¹
                    server_node = {
                        "name": server_name,
                        "label": f"{server_name} ğŸŒ",  # æ·»åŠ å›¾æ ‡æ ‡è¯†è¿œç¨‹æœåŠ¡å™¨
                        "type": "directory",
                        "source": "remote",
                        "children": remote_tree
                    }
                    result.append(server_node)
            except Exception as e:
                print(f"[Remote] Failed to load server {server_name}: {e}")
                # å³ä½¿å¤±è´¥ä¹Ÿæ·»åŠ èŠ‚ç‚¹ï¼Œä½†æ ‡è®°ä¸ºä¸å¯ç”¨
                result.append({
                    "name": server_name,
                    "label": f"{server_name} ğŸŒ (è¿æ¥å¤±è´¥)",
                    "type": "directory",
                    "source": "remote",
                    "exists": False,
                    "children": []
                })
        
        return result

    def clear_log(self, file_name: str) -> bool:
        """æ¸…ç©ºæ—¥å¿—æ–‡ä»¶ï¼ˆæœ¬åœ°æˆ–è¿œç¨‹ï¼‰"""
        file_conf = self.files_map.get(file_name)
        if not file_conf:
            return False
        
        source = file_conf.get("source", "local")
        
        if source == "local":
            # æœ¬åœ°æ–‡ä»¶
            path = file_conf["path"]
            if os.path.exists(path):
                with open(path, 'w'):
                    pass
                return True
            return False
        else:
            # è¿œç¨‹æ–‡ä»¶ - éœ€è¦å¼‚æ­¥å¤„ç†ï¼Œè¿™é‡Œè¿”å› Falseï¼Œå®é™…æ¸…ç©ºåœ¨ clear_log_async ä¸­
            return False
    
    async def clear_log_async(self, file_name: str) -> bool:
        """æ¸…ç©ºæ—¥å¿—æ–‡ä»¶ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼Œæ”¯æŒè¿œç¨‹ï¼‰"""
        file_conf = self.files_map.get(file_name)
        
        # å¦‚æœåœ¨ files_map ä¸­æ‰¾ä¸åˆ°ï¼Œå°è¯•è§£æè¿œç¨‹ç›®å½•æ–‡ä»¶
        if not file_conf:
            file_conf = await self._resolve_remote_file(file_name)
        
        if not file_conf:
            return False
        
        source = file_conf.get("source", "local")
        
        if source == "local":
            # æœ¬åœ°æ–‡ä»¶
            path = file_conf.get("path")
            if path and os.path.exists(path):
                with open(path, 'w'):
                    pass
                return True
            return False
        else:
            # è¿œç¨‹æ–‡ä»¶
            server_config = file_conf.get("server_config")
            file_path = file_conf.get("path")
            if server_config and file_path:
                return await self.remote_reader.clear_file(server_config, file_path)
            return False

    async def tail_file(self, file_name: str, request_args: dict) -> AsyncGenerator[Dict[str, str], None]:
        """
        ç”Ÿæˆå™¨ï¼šå®æ—¶è¯»å–æ—¥å¿—æ–‡ä»¶ï¼ˆæœ¬åœ°æˆ–è¿œç¨‹ï¼‰
        yields: æ ¼å¼åŒ–çš„ SSE æ•°æ®å—
        """
        file_conf = self.files_map.get(file_name)
        
        # å¦‚æœåœ¨ files_map ä¸­æ‰¾ä¸åˆ°ï¼Œå°è¯•è§£æè¿œç¨‹ç›®å½•æ–‡ä»¶
        if not file_conf:
            file_conf = await self._resolve_remote_file(file_name)
        
        if not file_conf:
            yield {"data": "[SYSTEM] File not found or configured incorrectly."}
            return
        
        source = file_conf.get("source", "local")
        
        if source == "remote":
            # è¿œç¨‹æ–‡ä»¶
            server_config = file_conf.get("server_config")
            file_path = file_conf.get("path")
            encoding = file_conf.get("encoding", "utf-8")
            
            if not server_config or not file_path:
                yield {"data": "[SYSTEM] Remote file configuration error."}
                return
            
            # ä½¿ç”¨è¿œç¨‹è¯»å–å™¨
            async for log_data in self.remote_reader.tail_file(server_config, file_path, encoding):
                yield log_data
            return
        
        # æœ¬åœ°æ–‡ä»¶å¤„ç†ï¼ˆå¼‚æ­¥ + æ–‡ä»¶ç›‘æ§ï¼‰
        file_path = file_conf.get("path")
        if not os.path.exists(file_path):
            yield {"data": "[SYSTEM] File not found or configured incorrectly."}
            return

        encoding = file_conf.get("encoding", "utf-8")
        
        # æ–‡ä»¶ä¿®æ”¹äº‹ä»¶æ ‡å¿—
        file_modified = asyncio.Event()
        
        try:
            # åˆå§‹è¯»å–å†å²æ—¥å¿—ï¼ˆå¼‚æ­¥ï¼‰
            async with aiofiles.open(file_path, 'r', encoding=encoding, errors='replace') as fp:
                # è·å–æ–‡ä»¶å¤§å°
                file_size = os.path.getsize(file_path)
                if file_size > 0:
                    # è¯»å–æœ€å 10KB
                    read_size = min(file_size, 1024 * 10)
                    await fp.seek(file_size - read_size)
                    
                    # ä¸¢å¼ƒç¬¬ä¸€è¡Œå¯èƒ½ä¸å®Œæ•´çš„æ•°æ®
                    if read_size < file_size:
                        await fp.readline()
                    
                    # è¯»å–å¹¶å‘é€ç°æœ‰å†…å®¹
                    async for line in fp:
                        if line.strip():
                            clean_line = strip_ansi_codes(line.strip())
                            yield {"data": clean_line}
            
            # è·å–å½“å‰æ–‡ä»¶ä½ç½®ï¼ˆç”¨äºåç»­è¯»å–ï¼‰
            current_position = os.path.getsize(file_path)
            
            # å¯åŠ¨æ–‡ä»¶ç›‘æ§ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
            observer = Observer()
            watch_dir = os.path.dirname(file_path)
            loop = asyncio.get_event_loop()
            
            event_handler = FileWatcher(file_path, file_modified, loop)
            observer.schedule(event_handler, watch_dir, recursive=False)
            observer.start()
            
            try:
                # å®æ—¶è¯»å–å¾ªç¯
                while True:
                    # ç­‰å¾…æ–‡ä»¶ä¿®æ”¹äº‹ä»¶ï¼ˆå¸¦è¶…æ—¶ï¼‰
                    try:
                        await asyncio.wait_for(file_modified.wait(), timeout=2.0)
                        file_modified.clear()
                    except asyncio.TimeoutError:
                        # è¶…æ—¶ï¼Œæ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä»ç„¶å­˜åœ¨
                        if not os.path.exists(file_path):
                            yield {"data": "[SYSTEM] File disappeared."}
                            break
                        continue
                    
                    # æ–‡ä»¶è¢«ä¿®æ”¹ï¼Œè¯»å–æ–°å†…å®¹
                    try:
                        new_size = os.path.getsize(file_path)
                        
                        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¢«æˆªæ–­
                        if new_size < current_position:
                            yield {"data": "[SYSTEM] File truncated. Reloading..."}
                            current_position = 0
                        
                        # è¯»å–æ–°è¡Œ
                        async with aiofiles.open(file_path, 'r', encoding=encoding, errors='replace') as fp:
                            await fp.seek(current_position)
                            async for line in fp:
                                if line.strip():
                                    clean_line = strip_ansi_codes(line.strip())
                                    yield {"data": clean_line}
                            current_position = await fp.tell()
                    
                    except OSError as e:
                        # æ–‡ä»¶å¯èƒ½æ­£åœ¨è¢«è½®è½¬
                        await asyncio.sleep(0.1)
                        continue
            
            finally:
                observer.stop()
                observer.join(timeout=1)
        
        except Exception as e:
            yield {"data": f"[SYSTEM] Error reading file: {str(e)}"}
    
    async def _resolve_remote_file(self, file_name: str) -> Optional[Dict]:
        """
        è§£æè¿œç¨‹æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºåŠ¨æ€æ‰«æçš„ç›®å½•æ–‡ä»¶ï¼‰
        file_name æ ¼å¼: "æœåŠ¡å™¨å/ç›®å½•å/ç›¸å¯¹è·¯å¾„"
        """
        # å°è¯•åŒ¹é…è¿œç¨‹æœåŠ¡å™¨é…ç½®
        for server_config in self.config.get("remote_servers", []):
            server_name = server_config.get("name", "Remote")
            
            # æ£€æŸ¥ file_name æ˜¯å¦ä»¥æœåŠ¡å™¨åå¼€å¤´
            if not file_name.startswith(f"{server_name}/"):
                continue
            
            # ç§»é™¤æœåŠ¡å™¨åå‰ç¼€
            remaining_path = file_name[len(server_name) + 1:]
            
            # éå†è¯¥æœåŠ¡å™¨çš„æ—¥å¿—é…ç½®
            for log_config in server_config.get("logs", []):
                log_name = log_config.get("name")
                log_type = log_config.get("type", "file")
                
                # å¦‚æœæ˜¯ç›®å½•ç±»å‹ï¼Œå°è¯•åŒ¹é…
                if log_type == "directory" and remaining_path.startswith(f"{log_name}/"):
                    # æå–ç›¸å¯¹è·¯å¾„
                    rel_path = remaining_path[len(log_name) + 1:]
                    base_path = log_config.get("path")
                    
                    # æ„å»ºå®Œæ•´è·¯å¾„
                    full_path = os.path.join(base_path, rel_path)
                    
                    return {
                        "path": full_path,
                        "encoding": "utf-8",
                        "source": "remote",
                        "server_config": server_config
                    }
        
        return None
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        await self.ssh_pool.close_all()
